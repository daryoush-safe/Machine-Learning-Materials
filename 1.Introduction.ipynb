{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540db15b",
   "metadata": {},
   "source": [
    "# Course Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf71b0",
   "metadata": {},
   "source": [
    "* **Supervised Learning**  \n",
    "    Learn to predict outcomes using labeled data\n",
    "\n",
    "* **Unsupervised Learning**  \n",
    "    Find patterns in unlabeled data\n",
    "\n",
    "* **Reinforcement Learning**  \n",
    "    Partial(indirect) feedback, no explicit guidance  \n",
    "    Given reward for a sequence of moves to learn a policy and utility function\n",
    "\n",
    "* **Neural Networks**  \n",
    "    Mimic the human brain to solve complex tasks    \n",
    "\n",
    "* **Computer Vision**  \n",
    "    Enable machines to see and interpret images    \n",
    "\n",
    "* **Natural Language Processing (NLP)**  \n",
    "    Understand and generate human language in text or voice format\n",
    "\n",
    "* **Contrastive Language-Image Pre training (CLIP)**  \n",
    "    Connecting text and images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689da7f5",
   "metadata": {},
   "source": [
    "# What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9feebed",
   "metadata": {},
   "source": [
    "* A field of study that enables computers to learn from data without being explicitly programmed.\n",
    "\n",
    "\n",
    "* Tom Mitchel (1998): Well-posed learning problem:  \n",
    "    A computer program is said to learn from **experience E** with respect to some class of **tasks T** and **performance measure P**, if its performance at tasks in **T**, as measured by **P**, improves with experience **E**.  \n",
    "    Learning Problem = (T,P,E)\n",
    "\n",
    "* Goal:  \n",
    "    Develop models that make accurate predictions based on past data.\n",
    "\n",
    "* The essence of machine learning:\n",
    "    1. A pattern exists  \n",
    "    2. We do not know it mathematically  \n",
    "    3. We have data on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8151bd",
   "metadata": {},
   "source": [
    "# Statistics & Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a407ef",
   "metadata": {},
   "source": [
    "## Statistical Models in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90102aef",
   "metadata": {},
   "source": [
    "* Target model in the learning problems can be considered as a statistical model.\n",
    "\n",
    "* For a fixed set of data and underlying target (statistical model), the estimation methods try to estimate the target from available data.\n",
    "\n",
    "* **Goal:** Estimating the probability density function $p(x)$, given a set of data $x^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44896b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* **Main approaches:**\n",
    "    - **Parametric:** Assuming a parameterized model for density function.  \n",
    "        - A number of parameters are optimized by fitting the model to the data set\n",
    "\n",
    "    - **Non-parametric (Instance-based):** No specific parametric model is assumed.  \n",
    "        - The form of density function is determined entirely by the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dca440",
   "metadata": {},
   "source": [
    "## Parametric Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e35229",
   "metadata": {},
   "source": [
    "**Goal**: Estimate parameters $(\\theta)$ of a distribution from a dataset $D = \\{x_1, x_2, ..., x_N\\}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798db454",
   "metadata": {},
   "source": [
    "### **Maximum Likelihood Estimation (MLE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c1db3",
   "metadata": {},
   "source": [
    "#### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663c4e7",
   "metadata": {},
   "source": [
    "*MLE* is a method of estimating the parameters of a statistical model given data.\n",
    "\n",
    "Likelihood is the conditional probability of observations $D = \\{x_1, x_2, ..., x_N\\}$ given the value of parameters $\\theta$ (assuming *independent*, *identical* *distributed* *(i.i.d.)* samples)  \n",
    "This approach tends to overfit to $D$.\n",
    "\n",
    "$$p(D | \\theta) = \\prod_{i=1}^N p(x^{(i)} | \\theta) = p(x_1 | \\theta)p(x_2 | \\theta)...p(x_N | \\theta)$$\n",
    "\n",
    "Maximum Likelihood Estimation (MLE):\n",
    "$$\\hat{\\theta}_{ML} = argmax_{\\theta}\\ p(D | \\theta)$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"images/MLE.png\" alt=\"MaximumLikelihood Estimation Example\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a376d",
   "metadata": {},
   "source": [
    "**Key Argument**:  \n",
    "Logarithms convert *products* (prone to underflow and hard to differentiate) into *sums* (stable and algebraically convenient):  \n",
    "\n",
    "$$\\log \\left( \\prod_{i} a_i \\right) = \\sum_{i} \\log a_i$$  \n",
    "\n",
    "So we have:\n",
    "\n",
    "$$L(\\theta) = \\ln p(D |\\theta) = \\ln \\prod_{i=1}^N p(x^{(i)} | \\theta) = \\sum_{i=1}^{N} \\ln p(x^{(i)} | \\theta)$$\n",
    "\n",
    "$$\\hat{\\theta}_{ML} = argmax_{\\theta}\\ L(\\theta) = argmax_{\\theta}\\ \\sum_{i=1}^{N} \\ln p(x^{(i)} | \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152c7df",
   "metadata": {},
   "source": [
    "#### **MLE Bernoulli**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed159bb5",
   "metadata": {},
   "source": [
    "* **Bernoulli:** given $x \\in \\{0, 1\\}$ then $p(x=1|\\theta) = \\theta$ and $p(x=0|\\theta) = 1-\\theta$\n",
    "\n",
    "* **MLE Bernoulli:** given $D = \\{x_1, x_2, ..., x_N\\}$, $m$ heads (1), $N-m$ tails (0).\n",
    "$$p(x|\\theta) = \\theta^x(1-\\theta)^{1-x}$$\n",
    "\n",
    "* So we have:\n",
    "$$p(D | \\theta) = \\prod_{i=1}^N p(x^{(i)} | \\theta) = \\prod_{i=1}^N \\theta^{x^{(i)}}(1-\\theta)^{{1-x}^{(i)}}$$\n",
    "$$\\ln p(D | \\theta) = \\sum_{i=1}^{N} \\ln p(x^{(i)} | \\theta) = \\sum_{i=1}^{N} x^{(i)}\\ln \\theta + ({1-x}^{(i)})\\ln (1-\\theta)$$\n",
    "$$\\frac{\\partial \\ln p(\\mathcal{D}|\\theta)}{\\partial \\theta} = 0 \\Rightarrow \\theta_{ML} = \\frac{\\sum_{i=1}^{N} x^{(i)}}{N} = \\frac{m}{N}$$\n",
    "\n",
    "* This approach tends to overfit to $D$.  \n",
    "    - E.g: $D=\\{1,1,1\\}$ then $\\hat \\theta_{ML} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f22d32",
   "metadata": {},
   "source": [
    "#### **Multinomial Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559f19f",
   "metadata": {},
   "source": [
    "$$x = [x_1, x_2, ..., x_K]$$\n",
    "$$x_k \\in \\{0, 1\\}$$\n",
    "$$\\sum_{k=1}^{K} x_k = 1$$\n",
    "*E.g: $x = [0, 0, 0, 1, 0, 0]$; which k=6*\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\theta = [\\theta_1, \\theta_2, ..., \\theta_K]$$\n",
    "$$\\theta_k \\in [0, 1]$$\n",
    "$$\\sum_{k=1}^{K} \\theta_k = 1$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\theta_k = p(x_k = 1)$$\n",
    "$$P(x|\\theta) = \\prod_{k=1}^K \\theta_k^{x_k}$$\n",
    "*(only one $x_k$ is one)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff18e8b",
   "metadata": {},
   "source": [
    "Given:  \n",
    "$$D = \\{x^{(1)}, x^{(2)}, ..., x^{(N)}\\}$$\n",
    "$$p(D | \\theta) = \\prod_{i=1}^N p(x^{(i)} | \\theta) = \\prod_{i=1}^N \\prod_{k=1}^K \\theta_k^{x_k^{(i)}}$$\n",
    "Assume:  \n",
    "$$ N_k = \\sum_{i=1}^N x_k^{(i)}$$\n",
    "Then:\n",
    "$$p(D | \\theta) = \\prod_{k=1}^K \\theta_k^{N_k}$$\n",
    "Accept this *(we will prove it later)*:\n",
    "$$L(\\theta, \\lambda) = \\ln p(D|\\theta) + \\lambda(1-\\sum_{k=1}^K \\theta_k)$$\n",
    "Then:\n",
    "$$\\hat \\theta_k = \\frac{\\sum_{i=1}^{N} x_k^{(i)}}{N} = \\frac{N_k}{N}$$\n",
    "\n",
    "**Interpretation**: We can conclude that the probability $P(k)$ of the $k$-th instance is the ratio of its occurrence count to the total number of instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea722f7",
   "metadata": {},
   "source": [
    "#### **Gaussian (Normal) Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5a1b1",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "g(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x - \\mu}{\\sigma}\\right)^2}\n",
    "$$\n",
    "where:\n",
    "- $\\mu$ is the mean,\n",
    "- $\\sigma$ is the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c516776",
   "metadata": {},
   "source": [
    "**MLE for Gaussian with Unknown $\\mu$**\n",
    "1. **Log-Likelihood of a Single Sample**:\n",
    "   $$\n",
    "   \\ln p(x^{(i)}|\\mu) = -\\ln \\left( \\sqrt{2\\pi}\\sigma \\right) - \\frac{1}{2\\sigma^2} \\left( x^{(i)} - \\mu \\right)^2\n",
    "   $$\n",
    "   \n",
    "$$\n",
    "L(\\mu) = \\ln p(D |\\mu) = \\ln \\prod_{i=1}^N p(x^{(i)} | \\mu) = \\sum_{i=1}^{N} \\ln p(x^{(i)} | \\mu) = \\sum_{i=1}^{N} -\\ln \\left( \\sqrt{2\\pi}\\sigma \\right) - \\frac{1}{2\\sigma^2} \\left( x^{(i)} - \\mu \\right)^2\n",
    "$$\n",
    "2. **Derivative of Log-Likelihood**:\n",
    "   Set the derivative of the total log-likelihood $L(\\mu)$ to zero:\n",
    "   $$\n",
    "   \\frac{\\partial L(\\mu)}{\\partial\\mu} = 0 \\implies \\frac{\\partial}{\\partial\\mu} \\left( \\sum_{i=1}^N \\ln p(x^{(i)}|\\mu) \\right) = 0\n",
    "   $$\n",
    "\n",
    "3. **Solve for $\\mu$**:\n",
    "   $$\n",
    "   \\sum_{i=1}^N \\frac{1}{\\sigma^2} \\left( x^{(i)} - \\mu \\right) = 0 \\implies \\hat{\\mu}_{ML} = \\frac{1}{N} \\sum_{i=1}^N x^{(i)}\n",
    "   $$\n",
    "\n",
    "**Interpretation**:\n",
    "The MLE estimate $\\hat{\\mu}_{ML}$ is the sample mean, matching classical statistical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371845c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c877f82e",
   "metadata": {},
   "source": [
    "### **Maximum A Posterior (MAP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f706ef9",
   "metadata": {},
   "source": [
    "#### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848fec37",
   "metadata": {},
   "source": [
    "- $p(D|\\theta) \\rightarrow$ likelihood\n",
    "- $p(\\theta)\\rightarrow$ prior\n",
    "- $p(\\theta|D) \\rightarrow$ posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce5c5b5",
   "metadata": {},
   "source": [
    "* ***Maximum Likelihood Estimation (MLE)***  \n",
    "    - MLE finds the parameter values that maximize the likelihood of observing the given data:\n",
    "    $$\\hat{\\theta}_{ML} = \\argmax_{\\theta}\\ p(D | \\theta)$$\n",
    "    - Purely data-driven (ignores prior knowledge).\n",
    "    - Can overfit with limited data.\n",
    "<br><br>\n",
    "* ***Maximum A Posteriori (MAP) Estimation***\n",
    "    - MAP incorporates prior beliefs (as a probability distribution) and maximizes the posterior *(acts mathematically as adding some mock samples to the dataset.)*:\n",
    "    $$\\hat{\\theta}_{MAP} = \\argmax_{\\theta}\\ p(\\theta | D) = \\argmax_{\\theta}\\ p(\\theta)p(D|\\theta)$$\n",
    "    - Adds a prior term $p(\\theta)$ to regularize the estimate.\n",
    "    - Balances data evidence with prior knowledge.\n",
    "    - Reduces overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d45871",
   "metadata": {},
   "source": [
    "*MAP* Estimation:\n",
    "$$\\hat{\\theta}_{MAP} = \\argmax_{\\theta}\\ p(\\theta | D)$$\n",
    "Bayes' Theorem:\n",
    "$$p(\\theta | D) =\\frac{p(\\theta)p(D|\\theta)}{p(D)}$$\n",
    "And there is no effect of $\\theta$ on the denominator. So we have:\n",
    "$$\\hat{\\theta}_{MAP} = \\argmax_{\\theta}\\ p(\\theta)p(D|\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcda33",
   "metadata": {},
   "source": [
    "#### **MAP Estimation example for Gaussian (Unknown μ)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11632e5a",
   "metadata": {},
   "source": [
    "* **Likelihood**:\n",
    "$$p(D |\\mu) = \\prod_{i=1}^N p(x^{(i)} | \\mu) = \\prod_{i=1}^N \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x^{(i)} - \\mu}{\\sigma}\\right)^2}$$\n",
    "\n",
    "* **Prior**:\n",
    "$$p(\\mu) = \\frac{1}{\\sigma_0\\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{\\mu - \\mu_0}{\\sigma_0}\\right)^2}$$\n",
    "\n",
    "* **Posterior**:\n",
    "$$p(\\mu|D) \\propto p(D|\\mu)p(\\mu)$$\n",
    "$$\\ln p(\\mu | D) = \\ln {(p(\\mu) \\prod_{i=1}^N p(x^{(i)} | \\mu))} = \\ln p(\\mu) + \\ln \\prod_{i=1}^N p(x^{(i)} | \\mu)$$  \n",
    "$$\\ln p(\\mu) = -\\ln(\\sigma_0\\sqrt{2\\pi}) -\\frac{1}{2}\\left(\\frac{\\mu - \\mu_0}{\\sigma_0}\\right)^2$$\n",
    "$$\\ln \\prod_{i=1}^N p(x^{(i)} | \\mu) = \\sum_{i=1}^{N} -\\ln \\left( \\sqrt{2\\pi}\\sigma \\right) - \\frac{1}{2\\sigma^2} \\left( x^{(i)} - \\mu \\right)^2$$\n",
    "\n",
    "* **Derivative and Solution for μ**  \n",
    "  Step 1: Take the Derivative of the Log-Posterior  \n",
    "  $$\\frac{d}{d\\mu} \\ln p(\\mu|D) = \\frac{1}{\\sigma^2} \\sum_{i=1}^N (x^{(i)} - \\mu) - \\frac{1}{\\sigma_0^2} (\\mu - \\mu_0) = 0$$  \n",
    "  Step 2: Solve the Equation  \n",
    "  $$\\hat{\\mu}_{MAP} = \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{\\sum_{i=1}^N x^{(i)}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}} = \\frac{\\sigma^2 \\mu_0 + \\sigma_0^2 N \\bar{x}}{\\sigma^2 + N \\sigma_0^2} = \\frac{\\sigma^2} {\\sigma^2 + N \\sigma_0^2}\\mu_0 + \\frac{\\sigma_0^2 N} {\\sigma^2 + N \\sigma_0^2}\\mu_{ML}$$\n",
    "\n",
    "* **Interpretation of Results**\n",
    "1. **Weighted Average**:  \n",
    "   $\\hat{\\mu}_{MAP}$ combines prior $\\mu_0$ and data $\\bar{x}$.\n",
    "2. **Asymptotic Behavior**:  \n",
    "   - If $( \\sigma_0^2 \\gg \\sigma^2 )$, the prior becomes uninformative (flat Gaussian), and the MAP estimate reduces to the MLE again.\n",
    "   - With large $N$, $(\\hat{\\mu}_{MAP} \\approx \\hat{\\mu}_{MLE} = \\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x^{(i)})$.\n",
    "   <div style=\"text-align:center\">\n",
    "   <img src=\"images/MAP.png\" alt=\"Asymptotic Behavior\">\n",
    "   </div>\n",
    "3. **Posterior Precision**:  \n",
    "   $$\\frac{1}{\\sigma_N^2} = \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}$$\n",
    "   More samples $\\rightarrow$ Sharper Posterior $p(\\mu | D)$ $\\rightarrow$ Higher Confidence in Estimation\n",
    "   <div style=\"text-align:center\">\n",
    "   <img src=\"images/MAPHigherN.png\" alt=\"Asymptotic Behavior\">\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd417c4",
   "metadata": {},
   "source": [
    "#### **Conjugate Priors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff05c27",
   "metadata": {},
   "source": [
    "**definition:** A prior is chosen such that the posterior has the same functional form as the prior.   \n",
    "*In the Gaussian case (shown earlier), both the prior and posterior are Gaussian distributions.*\n",
    "\n",
    "$$p(\\theta|D) \\propto p(D|\\theta) p(\\theta)$$\n",
    "Key Terms:\n",
    "- $p(\\theta|D)$: Posterior distribution\n",
    "- $p(D|\\theta)$: Likelihood function\n",
    "- $p(\\theta)$: Prior distribution *(same functional form as the posterior)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10cd5ae",
   "metadata": {},
   "source": [
    "#### **Prior for Bernoulli**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c387b7",
   "metadata": {},
   "source": [
    "**Beta Distribution over $\\theta \\in [0,1]$**\n",
    "\n",
    "1. Probability Density Function\n",
    "$$\\text{Beta}(\\theta|\\alpha_1, \\alpha_0) \\propto \\theta^{\\alpha_1 - 1}(1 - \\theta)^{\\alpha_0 - 1}$$\n",
    "\n",
    "2. Normalized Form\n",
    "$$\\text{Beta}(\\theta|\\alpha_1, \\alpha_0) = \\frac{\\Gamma(\\alpha_0 + \\alpha_1)}{\\Gamma(\\alpha_0)\\Gamma(\\alpha_1)} \\theta^{\\alpha_1 - 1}(1 - \\theta)^{\\alpha_0 - 1}$$\n",
    "\n",
    "3. Key Properties\n",
    "- *Mean*:\n",
    "  $$E[\\theta] = \\frac{\\alpha_1}{\\alpha_0 + \\alpha_1}$$\n",
    "- *Mode (Most Probable $\\theta$)*:\n",
    "  $$\\hat{\\theta} = \\frac{\\alpha_1 - 1}{\\alpha_0 - 1 + \\alpha_1 - 1}$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"images/BetaDistribution.png\" alt=\"Beta Distribution\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7fd05",
   "metadata": {},
   "source": [
    "**Conjugate Prior Derivation**\n",
    "1. Bayesian Posterior Proportionality\n",
    "$$p(\\theta|D) \\propto p(D|\\theta)p(\\theta)$$\n",
    "2. Prior Distribution (Beta)\n",
    "$$p(\\theta) = \\theta^{\\alpha_1 - 1}(1 - \\theta)^{\\alpha_0 - 1}$$\n",
    "3. Likelihood:\n",
    "$$p(D |\\theta) = \\prod_{i=1}^N p(x^{(i)} | \\theta) = \\prod_{i=1}^N \\theta ^ {x^{(i)}}(1 - \\theta)^{(1-x^{(i)})}$$\n",
    "4. Combine Prior and Likelihood\n",
    "$$p(D|\\theta)p(\\theta) = \\theta ^ {(\\alpha_1 + \\sum_{i=1}^N x^{(i)} - 1)} + (1 - \\theta) ^ {(\\alpha_0 + \\sum_{i=1}^N (1-x^{(i)}) - 1)}$$\n",
    "5. Resulting Posterior (Beta)\n",
    "    The posterior is a Beta distribution with updated parameters:\n",
    "    $$p(\\theta|D) \\propto \\text{Beta}(\\theta | \\alpha_1', \\alpha_0')$$\n",
    "    Where ($m$ heads (1) and $N-m$ tails (0)):\n",
    "    $$\\alpha_1' = \\alpha_1 + \\sum_{i=1}^N x^{(i)} = \\alpha_1 + m$$\n",
    "    $$\\alpha_0' = \\alpha_0 + \\sum_{i=1}^N (1-x^{(i)}) = \\alpha_0 + N - m$$\n",
    "    $$\\hat{\\theta} = \\frac{\\alpha_1' - 1}{\\alpha_0' - 1 + \\alpha_1' - 1}$$\n",
    "**Conjugacy:** The posterior retains the Beta form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d6c5d",
   "metadata": {},
   "source": [
    "### **Bayesian Interference**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c0b50",
   "metadata": {},
   "source": [
    "#### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd9065",
   "metadata": {},
   "source": [
    "* **MLE (Maximum Likelihood Estimation)**: \n",
    "    - seeks a fixed point estimate for a parameters $\\theta$ by maximizing the likelihood:\n",
    "    $$\\hat{\\theta}_{ML} = \\argmax_{\\theta}\\ p(D | \\theta)$$\n",
    "    - Limitation: Ignores prior knowledge and parameter uncertainty.\n",
    "\n",
    "* **MAP (Maximum A posteriori)**:\n",
    "    - Extends MLE by incorporating a prior, but still returns a fixed point estimate:\n",
    "    $$\\hat{\\theta}_{MAP} = \\argmax_{\\theta}\\ p(\\theta | D) = \\argmax_{\\theta}\\ p(\\theta)p(D|\\theta)$$\n",
    "    - Limitation: Collapses the posterior to a single value, discarding uncertainty.\n",
    "\n",
    "* **Fully Bayesian**:\n",
    "    - Treats parameters $\\theta$ as random variables with a full posterior distribution $p(\\theta | D)$ and then compute the predictive distribution $p(x | D)$\n",
    "    - Does not fix $\\theta$ to a single value. Instead, it quantifies uncertainty by maintaining the entire distribution.\n",
    "    - Limitation: Needs higher computational complexity to calculating integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef1a93",
   "metadata": {},
   "source": [
    "#### **The Predictive Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a7487",
   "metadata": {},
   "source": [
    "To compute a predictive distribution $p(x | D)$ using posterior distribution:\n",
    "$$p(x | D) = \\int p(x,\\theta | D) {d}\\theta = \\int p(x | D,\\theta)p(\\theta| D) {d}\\theta = \\int p(x | \\theta)p(\\theta| D) {d}\\theta$$\n",
    "Where:  \n",
    "- $p(x | \\theta)$ is likelihood of $x$ given specific $\\theta$.\n",
    "- $p(\\theta | D)$ is posterior belief over $\\theta$ after observing data $D$.\n",
    "- The integral marginalizes over $\\theta$, averaging predictions across all possible $\\theta$ values, weighted by their posteriori probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad36e0",
   "metadata": {},
   "source": [
    "Weighting Mechanism:  \n",
    "- The posterior $p(\\theta ∣ D)$ acts as a *weight* for each $\\theta$, reflecting how much we believe in that parameter value after seeing the data.\n",
    "- Example: If $p(\\theta_1 | D)$ is high, predictions using $\\theta_1$ contribute more to $p(x | D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd1387",
   "metadata": {},
   "source": [
    "#### **When Fully Bayesian ≈ MAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5dd43",
   "metadata": {},
   "source": [
    "When the posterior distribution collapses to a single point. *(posterior variance $\\sigma_N^2 \\to 0$)*  \n",
    "Posterior Precision:  \n",
    "   $$\\frac{1}{\\sigma_N^2} = \\frac{1}{\\sigma_0^2} + \\frac{N}{\\sigma^2}$$\n",
    "When $\\sigma_N^2 \\to 0$:\n",
    "- Large Data ($N \\to \\infty$) *proved before*\n",
    "- Strong Prior ($\\sigma_0^2 \\to 0$)\n",
    "- Low Data Noise ($\\sigma_0^2 \\to 0$)\n",
    "\n",
    "Mechanism:  \n",
    "  - Posterior becomes a delta function $\\delta(\\theta - \\mu_N)$.  \n",
    "  - Predictive integral reduces to $p(x|\\mu_N)$.  \n",
    "\n",
    "Implication:  \n",
    "  - Bayesian uncertainty vanishes ⇒ MAP and Bayesian predictions align.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e8de1",
   "metadata": {},
   "source": [
    "#### **Example: Bernoulli Likelihood: prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126df0b",
   "metadata": {},
   "source": [
    "1. Prior and Posterior Distributions\n",
    "We showed in the conjugacy section:\n",
    "* Prior:\n",
    "    $$p(\\theta) = \\theta^{\\alpha_1 - 1}(1 - \\theta)^{\\alpha_0 - 1}$$\n",
    "* Posterior:\n",
    "    $$p(\\theta|D) \\propto \\text{Beta}(\\theta | \\alpha_1', \\alpha_0')$$\n",
    "    With updated parameters (for $m$ heads(1) and $N-m$ tails(0)):\n",
    "    $$\\alpha_1' = \\alpha_1 + \\sum_{i=1}^N x^{(i)} = \\alpha_1 + m$$\n",
    "    $$\\alpha_0' = \\alpha_0 + \\sum_{i=1}^N (1-x^{(i)}) = \\alpha_0 + N - m$$\n",
    "    Thus:\n",
    "    $$p(\\theta|D) = \\theta ^ {(\\alpha_1 + m - 1)} + (1 - \\theta) ^ {(\\alpha_0 + (N - m) - 1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af470c95",
   "metadata": {},
   "source": [
    "2. Predictive Distribution\n",
    "    The predictive distribution for data x is:\n",
    "    $$p(x | D) = \\int p(x | \\theta)p(\\theta| D) {d}\\theta$$\n",
    "    This is equivalent to taking the expectation over the posterior (since we already know its formula):\n",
    "    $$E[f(x)] = \\int f(x)p(x){d}x$$\n",
    "    $$p(x | D) = E_{p(\\theta | D)}[p(x | \\theta)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884bedce",
   "metadata": {},
   "source": [
    "3. Solving for $p(x=1 | D)$:\n",
    "    Likelihood:\n",
    "    $$p(x | \\theta) = \\theta^x(1 - \\theta)^{(1 - x)} \\rightarrow p(x=1 | \\theta) = \\theta$$\n",
    "    Posterior Expectation: of $\\theta$ under a Beta distribution:\n",
    "    $$E[\\theta] = \\frac{\\alpha_1'}{\\alpha_0' + \\alpha_1'}$$\n",
    "    result:\n",
    "    $$p(x=1 | D) = E_{p(\\theta | D)}[\\theta] = \\frac{\\alpha_1 + m}{\\alpha_0 + \\alpha_1 + N}$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
